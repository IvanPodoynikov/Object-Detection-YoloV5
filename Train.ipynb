{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7pPmypAGuBm"
      },
      "source": [
        "<h1 style=\"text-align: center;\"><b>Object detection</b></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tip: Use GPU Acceleration"
      ],
      "metadata": {
        "id": "sgTB-okboOBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are running this notebook in Google Colab, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`. This will ensure your notebook uses a `GPU`, which will significantly speed up model training times."
      ],
      "metadata": {
        "id": "KWe_5MZNoVkd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing a custom dataset"
      ],
      "metadata": {
        "id": "lvma4ldSs_YX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading necessary libraries"
      ],
      "metadata": {
        "id": "xKyiVmGUtHVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import os.path\n",
        "from os import path\n",
        "import shutil\n",
        "import tqdm\n",
        "import cv2"
      ],
      "metadata": {
        "id": "jbBE71OTtGl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will get <a href=\"http://shuoyang1213.me/WIDERFACE/\">Wider Train</a> from my Google Drive"
      ],
      "metadata": {
        "id": "WZpo7vQzmvA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HOME = os.getcwd()\n",
        "HOME"
      ],
      "metadata": {
        "id": "db7d40Aom-Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(f'{HOME}/drive')"
      ],
      "metadata": {
        "id": "a9BQTb6MfpQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For training *YoloV8* we need to preprocess data so that it looks:  \n",
        "![](https://raw.githubusercontent.com/IvanPodoynikov/YoloV8-Object-Detection/main/assets/YoloV8DataFormat.jpeg)"
      ],
      "metadata": {
        "id": "6TfoZrtcqGOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Making directories to fit the format"
      ],
      "metadata": {
        "id": "AM6Qo4WznfSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "AIBjHjFQQQHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(f'{HOME}/Face_dataset') == False:\n",
        "  os.mkdir(f'{HOME}/Face_dataset')"
      ],
      "metadata": {
        "id": "LAHMOIhlGgbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(f'{HOME}/Face_dataset/train') == False:\n",
        "  os.mkdir(f'{HOME}/Face_dataset/train')\n",
        "if os.path.exists(f'{HOME}/Face_Dataset/valid') == False:\n",
        "  os.mkdir(f'{HOME}/Face_dataset/valid')"
      ],
      "metadata": {
        "id": "hVxsbztmET7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(f'{HOME}/Face_dataset/train/images') == False:\n",
        "  os.mkdir(f'{HOME}/Face_dataset/train/images')\n",
        "if os.path.exists(f'{HOME}/Face_dataset/train/labels') == False:\n",
        "  os.mkdir(f'{HOME}/Face_dataset/train/labels')\n",
        "\n",
        "if os.path.exists(f'{HOME}/Face_dataset/valid/images') == False:\n",
        "  os.mkdir(f'{HOME}/Face_dataset/valid/images')\n",
        "if os.path.exists(f'{HOME}/Face_dataset/valid/labels') == False:\n",
        "  os.mkdir(f'{HOME}/Face_dataset/valid/labels')"
      ],
      "metadata": {
        "id": "YeI3wg1Kzs6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.unpack_archive(f\"{HOME}/drive/MyDrive/ColabNotebooks/WIDER_train.zip\", f'{HOME}') # There indicate your path to WIDER_train\n",
        "shutil.unpack_archive(f\"{HOME}/drive/MyDrive/ColabNotebooks/WIDER_val.zip\", f'{HOME}')   # There indicate your path to WIDER_val"
      ],
      "metadata": {
        "id": "o_6AvRk7K8TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.unpack_archive(f\"{HOME}/drive/MyDrive/ColabNotebooks/wider_face_split.zip\", f'{HOME}') # There indicate your path to wider_face_split"
      ],
      "metadata": {
        "id": "1shs_nwMJr9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making YAML"
      ],
      "metadata": {
        "id": "hjEdAe9v0pA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"dataV8.yaml\", \"w\") as f:\n",
        "    f.write(f\"names:\\n- face\\nnc: 1\\n\\ntrain: {HOME}/Face_dataset/train/images\\nval: {HOME}/Face_dataset/valid/images\")"
      ],
      "metadata": {
        "id": "dClWgVVzz7tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If You use MAC, uncomment next line"
      ],
      "metadata": {
        "id": "8nhXT6uI0n6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf __MACOSX"
      ],
      "metadata": {
        "id": "05V7OioyJwVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want to move files to *Face_dataset* from *WIDER_train* and *WIDER_val*"
      ],
      "metadata": {
        "id": "FUY-Wzgp9-zB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.move(f'{HOME}/dataV8.yaml', f'{HOME}/Face_dataset')"
      ],
      "metadata": {
        "id": "VbALGMC6GT8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = f'{HOME}/WIDER_train/images'\n",
        "for folder in os.listdir(directory):\n",
        "    for image in os.listdir(str(directory + '/' + folder)):\n",
        "        shutil.move(str(directory + '/' + folder + '/' + image), f'{HOME}/Face_dataset/train/images')\n",
        "directory = f'{HOME}/WIDER_val/images'\n",
        "for folder in os.listdir(directory):\n",
        "    for image in os.listdir(str(directory + '/' + folder)):\n",
        "        shutil.move(str(directory + '/' + folder + '/' + image), f'{HOME}/Face_dataset/valid/images')"
      ],
      "metadata": {
        "id": "2aN8KyfaHwzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree(f'{HOME}/WIDER_train')\n",
        "shutil.rmtree(f'{HOME}/WIDER_val')"
      ],
      "metadata": {
        "id": "TcarP-uS9uuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see, what *wider_face_split* contains"
      ],
      "metadata": {
        "id": "wN_cVxqW1-pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = f'{HOME}/wider_face_split/wider_face_train_bbx_gt.txt'\n",
        "df_train = pd.read_csv(path, header = None)\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "ZWxm1EwSNumz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = f'{HOME}/wider_face_split/wider_face_val_bbx_gt.txt'\n",
        "df_val = pd.read_csv(path, header = None)\n",
        "df_val.head()"
      ],
      "metadata": {
        "id": "AdI_F9ST6Dz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting bboxes for each image"
      ],
      "metadata": {
        "id": "dhriwHhz2AZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_filenames_bboxes(df):\n",
        "  filenames = []\n",
        "  bboxes = {}\n",
        "  i = 0\n",
        "  while i < len(df):\n",
        "      if df[0][i].split(\".\")[-1] == \"jpg\":\n",
        "\n",
        "          cur_filename = df[0][i].split(\"/\")[-1]\n",
        "          filenames.append(cur_filename)\n",
        "\n",
        "          count_bboxes = int(df[0][i+1])\n",
        "          bboxes[cur_filename] = []\n",
        "          i = i + 1\n",
        "\n",
        "          for j in range(count_bboxes):\n",
        "              bboxes[cur_filename].append(df[0][i+j+1].split(' ')[:4])\n",
        "\n",
        "          bboxes[cur_filename] = np.array(bboxes[cur_filename])\n",
        "          i = i + count_bboxes\n",
        "\n",
        "      i = i + 1\n",
        "  filenames.sort()\n",
        "  return (filenames, bboxes)"
      ],
      "metadata": {
        "id": "rE6uxr73PefK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames_train, bboxes_train = make_filenames_bboxes(df_train)\n",
        "filenames_val, bboxes_val = make_filenames_bboxes(df_val)"
      ],
      "metadata": {
        "id": "Jo-kqZeHcgDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see example"
      ],
      "metadata": {
        "id": "4smI2UmJ0q3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filenames_train[0]"
      ],
      "metadata": {
        "id": "yVRRF78t-f8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bboxes_train['0_Parade_Parade_0_1014.jpg'])\n",
        "print(type(bboxes_train['0_Parade_Parade_0_1014.jpg'][0][0]))\n",
        "print(bboxes_train['0_Parade_Parade_0_1014.jpg'][0][0])"
      ],
      "metadata": {
        "id": "7NbGvPMmXsm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now write a function that will take the annotations in given format <a href=\"http://shuoyang1213.me/WIDERFACE/\">(from here)</a> and convert them to a format where information about the bounding boxes is stored in a dictionary, like this (example for many classes):  \n",
        "{'bboxes':  \n",
        "[{'class': 'trafficlight', 'xmin': 20, 'ymin': 109, 'xmax': 81, 'ymax': 237},  \n",
        "{'class': 'trafficlight', 'xmin': 116, 'ymin': 162, 'xmax': 163, 'ymax': 272},  \n",
        "{'class': 'trafficlight', 'xmin': 189, 'ymin': 189, 'xmax': 233, 'ymax': 295}],  \n",
        "'filename': 'road4.png',  \n",
        "'image_size': (267, 400, 3)}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6geyWinbAbdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_info_dict(filename, bboxes, sample): # We give: name of the file, its bboxes, type(I called it sample): train / val / test\n",
        "    root = f'{HOME}/Face_dataset/{sample}/images'\n",
        "    info_dict = {}\n",
        "\n",
        "    info_dict['bboxes'] = []\n",
        "    if len(bboxes) != 0:\n",
        "      array_of_classes = np.array([[0] for i in range(bboxes.shape[0])])\n",
        "      # list if all bboxes, we add 'class' manually to get this format: class, x_min, y_min, width, height\n",
        "      lsts = np.concatenate((array_of_classes, bboxes), axis = 1).tolist()\n",
        "\n",
        "      # get info_dict\n",
        "      for lst in lsts:\n",
        "          bbox = {}\n",
        "\n",
        "          cl = 'face'\n",
        "          x_min = int(lst[1])\n",
        "          y_min = int(lst[2])\n",
        "          x_max = x_min + int(lst[3])\n",
        "          y_max = y_min + int(lst[4])\n",
        "\n",
        "          bbox['class'] = cl\n",
        "          bbox['x_min'] = x_min\n",
        "          bbox['y_min'] = y_min\n",
        "          bbox['x_max'] = x_max\n",
        "          bbox['y_max'] = y_max\n",
        "\n",
        "          info_dict['bboxes'].append(bbox)\n",
        "\n",
        "    info_dict['filename'] = filename\n",
        "    im = cv2.imread(root+'/' + filename)\n",
        "    info_dict['image_size'] = im.shape\n",
        "\n",
        "    return info_dict"
      ],
      "metadata": {
        "id": "FNKKe_g3Amc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This outputs:"
      ],
      "metadata": {
        "id": "4ljGAs8oQ97s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = filenames_train[1]\n",
        "get_info_dict(filename, bboxes_train[filename], 'train')"
      ],
      "metadata": {
        "id": "wjupt_M_BBhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = filenames_val[2]\n",
        "get_info_dict(filename, bboxes_val[filename], 'valid')"
      ],
      "metadata": {
        "id": "DOqNUQde0wdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got a convenient file format.  \n",
        "Now we write a function to convert info contained in `info_dict` to YoloV8 style annotations and write them to a `txt` file\n"
      ],
      "metadata": {
        "id": "jGEaHWFJfC5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_yolov8(info_dict, sample):\n",
        "    class_name_to_id_mapping = {'face': 0}\n",
        "    print_buffer = []\n",
        "\n",
        "    # For each bounding box\n",
        "    for i, b in enumerate(info_dict[\"bboxes\"]):\n",
        "        try:\n",
        "            class_id = class_name_to_id_mapping[b[\"class\"]]\n",
        "        except KeyError:\n",
        "            print(\"Invalid Class. Must be one from \", class_name_to_id_mapping.keys())\n",
        "\n",
        "        # Transform the bbox co-ordinates as per the format required by YOLO v8\n",
        "        b_center_x = (b[\"x_min\"] + b[\"x_max\"]) / 2\n",
        "        b_center_y = (b[\"y_min\"] + b[\"y_max\"]) / 2\n",
        "        b_width    = (b[\"x_max\"] - b[\"x_min\"])\n",
        "        b_height   = (b[\"y_max\"] - b[\"y_min\"])\n",
        "\n",
        "        # Normalise the co-ordinates by the dimensions of the image\n",
        "        image_h, image_w, image_c = info_dict[\"image_size\"]\n",
        "        b_center_x /= image_w\n",
        "        b_center_y /= image_h\n",
        "        b_width    /= image_w\n",
        "        b_height   /= image_h\n",
        "\n",
        "        #Write the bbox details to the file\n",
        "        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))\n",
        "    # Name of the file which we have to save\n",
        "    save_file_name = os.path.join(f'{HOME}/Face_dataset/{sample}/labels', info_dict[\"filename\"].replace(\"jpg\", \"txt\"))\n",
        "\n",
        "    # Save the annotations to file\n",
        "    print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))"
      ],
      "metadata": {
        "id": "ih_Vo7AAfKJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, filename in enumerate(filenames_train):\n",
        "    info_dict = get_info_dict(filename, bboxes_train[filename], 'train')\n",
        "    convert_to_yolov8(info_dict, 'train')"
      ],
      "metadata": {
        "id": "NAmd6OYUg6rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, filename in enumerate(filenames_val):\n",
        "    info_dict = get_info_dict(filename, bboxes_val[filename], 'valid')\n",
        "    convert_to_yolov8(info_dict, 'valid')"
      ],
      "metadata": {
        "id": "MmE8df8BGoxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "a17sq5rE64e4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I got two errors:**  \n",
        "---train: WARNING ⚠️ /content/Face_Dataset/images/train/54_Rescue_rescuepeople_54_29.jpg:  \n",
        "ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.025]  \n",
        "---val: WARNING ⚠️ /content/Face_Dataset/images/val/39_Ice_Skating_iceskiing_39_583.jpg:  \n",
        "ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]  \n",
        "That is not my fault, I checked manually, there is a mistake in coordinates in `txt` file:  \n",
        "In the first case image has width = 1024 with x_min = x_max = 1050   \n",
        "In the second case image has width = 1024 with x_max = 1026  \n",
        "**Yolo will skip these images during training**\n"
      ],
      "metadata": {
        "id": "m0sCHfwYO4Hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "mZ_0dQcoLzWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "lxdpxH0RLqH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8n.yaml')\n",
        "model.to(device);"
      ],
      "metadata": {
        "id": "pi2Ug7AHL3CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = f'{HOME}/Face_dataset/dataV8.yaml'\n",
        "path"
      ],
      "metadata": {
        "id": "A3WDlsVTMAtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(data = path, epochs = 5, imgsz = 640)"
      ],
      "metadata": {
        "id": "QlrYmw4K_wa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "XfFkGY_SK3TO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results saved in ./runs  \n",
        "We need ./runs/detect/train/weights/best.pt for Streamlit  \n",
        "We have to download this file and follow instructions on Git"
      ],
      "metadata": {
        "id": "iqYP6ABObwBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics and Losses"
      ],
      "metadata": {
        "id": "dxtET8H_Ncnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im = plt.imread(f'{HOME}/runs/detect/train/results.png')\n",
        "fig, ax = plt.subplots(figsize = (19.2, 10.8))\n",
        "ax.set_title('Results')\n",
        "ax.imshow(im);"
      ],
      "metadata": {
        "id": "DL5oUPAoNeud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions"
      ],
      "metadata": {
        "id": "pqGRbMhDOa0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im = plt.imread(f'{HOME}/runs/detect/train/val_batch0_labels.jpg')\n",
        "fig, ax = plt.subplots(figsize = (19.2, 10.8))\n",
        "ax.set_title('Prediction')\n",
        "ax.imshow(im);"
      ],
      "metadata": {
        "id": "Xoc9Yt8rOghz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im = plt.imread(f'{HOME}/runs/detect/train/val_batch1_labels.jpg')\n",
        "fig, ax = plt.subplots(figsize = (19.2, 10.8))\n",
        "ax.set_title('Prediction')\n",
        "ax.imshow(im);"
      ],
      "metadata": {
        "id": "YnxztFOCO5Ii"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
